"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"WLXH7GLU","journalArticle","2010","Bowers, Alex J.","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Practical Assessment, Research & Evaluation","","1531-7714","","","School personnel currently lack an effective method to pattern and visually interpret disaggregated achievement data collected on students as a means to help inform decision making. This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. Additionally, as a proof-of-concept study, overall schooling outcomes, such as student dropout or taking a college entrance exam, are identified from the data patterns and compared to past methods of dropout identification as one example of the usefulness of the method. Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8. (Contains 5 figures.)","2010-05","2017-09-12 14:45:23","2017-09-12 14:45:23","2014-09-24 19:31:29","","","7","15","","","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students","","","","","","","en","","","","","ERIC","","","<ul style=""-en-clipboard: true;""> <li>The article made me understand how similar methods (clustering and data visualization) can be used in HR analytics, to predict turnover and absenteeism. Learning data mining in education can help me make sense of how data analytics can also be used in HR analytics / organization analysis.</li> <li>The pictures in this article already contains a lot of useful information and implications for intervention. </li> <li>Some basic concepts:</li> <li style=""list-style: none;""> <ul> <li>3DM: data driven decision making</li> <li>SSF: success at school factor</li> <li>cluster tree / dendrogram — based on the distance calculation [uncentered correlation was used as the distance measure here]</li> <li style=""list-style: none;""> <ul> <li>shorter horizontal lines indicates more similarity; </li> <li>vertical lines connect the closest rows to form the clusters. each data row is clustered by similarity.</li> </ul> </li> <li>heatmap: hotter color indicates a higher score (red); cooler color indicates a lower score (blue); neural color indicates a central score (grey)</li> <li>hierarchical cluster analysis (HCA): supervised clustering — begins with a defined set of assumptions about the categorization of the data; unsupervised clustering — assumes nothing about the categorization and is designed to statistically discover the underlying structure patterns within the dataset, a procedure well suited to discovering the underlying patterns within student data in education.</li> <li>missing data might have patterns (average linkage can help to address the missing data issue)</li> <li>combination of the cluster analysis, cluster tree, and heat map, creates the clustergram</li> <li>can compared with categorical data as well</li> </ul> </li> <li>Some interesting things worth notice:</li> <li style=""list-style: none;""> <ul> <li>teacher-assigned grades is a weak indicator of academic knowledge when compared to standardized test score — 75% of teacher-assigned grades appear to assess a student’s ability to negotiate the social processes of school</li> <li>don’t forget the goal of the study. this is very important.</li> </ul> </li> </ul>","","http://eric.ed.gov/?id=EJ933686","","data; data analysis; Decision Making; Dropouts; Elementary School Students; Grades (Scholastic); Identification; MULTIVARIATE analysis; School Districts; Secondary School Students","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSXU84W9","journalArticle","2014","Grunspan, Daniel Z.; Wiggins, Benjamin L.; Goodreau, Steven M.","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","CBE-Life Sciences Education","",", 1931-7913","10.1187/cbe.13-08-0162","http://www.lifescied.org/content/13/2/167","Social interactions between students are a major and underexplored part of undergraduate education. Understanding how learning relationships form in undergraduate classrooms, as well as the impacts these relationships have on learning outcomes, can inform educators in unique ways and improve educational reform. Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. We introduce basic concepts in SNA, along with methods for data collection, data processing, and data analysis, using a previously collected example study on an undergraduate biology classroom as a tutorial. We conduct descriptive analyses of the structure of the network of costudying relationships. We explore generative processes that create observed study networks between students and also test for an association between network position and success on exams. We also cover practical issues, such as the unique aspects of human subjects review for network studies. Our aims are to convince readers that using SNA in classroom environments allows rich and informative analyses to take place and to provide some initial tools for doing so, in the process inspiring future educational studies incorporating relational data.","2014-06-20","2017-09-12 14:45:23","2017-09-12 14:45:23","2014-08-20 20:21:46","167-178","","2","13","","CBE Life Sci Educ","Understanding Classrooms through Social Network Analysis","","","","","","","en","","","","","www.lifescied.org","","","<ul> <li>From this article I learn some basic concepts, especially measurement of SNA. By contrasting SNA and conventional data, it is very clear. It is also great to go through a thorough research, like how to do the analysis, what are some limitations and things to keep in mind.</li> <li>Network Concepts</li> <li style=""list-style: none;""> <ul> <li>SNA aims to understand the determinants, structure, and consequences of relationships between actors; focus how individuals may have similar network positions due to shared attributes</li> <li>actors/nodes</li> <li>network types: </li> <li style=""list-style: none;""> <ul> <li>unipartite/monopartite/one-mode; bipartite/two-mode</li> <li>bidirectional/undirected; directed</li> <li>ties can be binary or valued</li> </ul> </li> </ul> <ul> <li>network data collection: egocentric; census/whole</li> <li>network level concepts and measure</li> <li style=""list-style: none;""> <ul> <li>density: how many links are observed in a whole network  divided by the total number of links that could exist; hard to interpret without comparable data from other similar networks; global metric that simply indicates how many ties are present </li> <li>homophily: a propensity for similar actors to be disproportionately connected in a relation of interest</li> <li>social selection: when a relationship is more likely to occur due to two actors having the same attributes</li> <li>social influence: when individuals change their attributes to match those of their relational partners, due to influence from those partners</li> <li>dyad-level analysis vs. triads</li> <li>triad census: count of how many different triad types exist in a network</li> <li>transitivity: value representing the likelihood of student A being tied to c</li> <li>transitive triad (A-&gt;B-&gt;C; hierarchy) vs. cyclical triad (A-&gt;C / C-&gt;A; egalitarianism)</li> </ul> </li> <li>actor-level variables</li> <li style=""list-style: none;""> <ul> <li>degree centrality: total number of connections a node has. in directional network, include measures of indegree and outdegree</li> <li>betweenness centrality: whether actors serve as bridges in the shortest paths between two actors</li> <li>closeness centrality: how close one actor is to other actors on average, measured along geodesics. it is a poorly suited for disconnected network.</li> <li>eigenvector centrality: being connected to other well-connected individuals.</li> </ul> </li> </ul> </li> <li>survey fatigue -&gt; it is important to avoid overuse of surveys</li> <li>pilot studies with your survey is important </li> <li>data management: nodal attributes vs. relational data (sociomatrix / adjacency matrix)</li> <li>SNA lends itself well to exploratory analyses, it is often judicious to have a priori hypotheses before beginning data collection. visualizing the network is often the first stem taken in performing SNA.</li> <li>always remember data dependence, like conduct permutation correlation test</li> <li>general measurements: edges; density; triad(0/1/2/3); transitivity</li> <li>degree distribution - view the increase in overall study partnership</li> <li>parallel coordinate plot - view general trends (the plot is beautiful and I want to learn!)</li> <li>test for association between exam scores and both degree centrality and betweenness centrality</li> </ul>","","http://www.lifescied.org/content/13/2/167","Week 2","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQX2JY7Q","blogPost","2014","Young, Jeffrey R.","Why Students Should Own Their Educational Data","The Chronicle of Higher Education Blogs: Wired Campus","","","","http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329","","2014-08-21","2017-09-12 14:45:24","2017-09-12 14:45:24","2014-08-23 21:32:22","","","","","","","","","","","","","","","","","","","","","","<ul style=""-en-clipboard: true;""> <li>Even there is not much details in this article, I love the idea that students should own their education data. We still face the core question - Who should own the data? Traditional standard teaching practice assumes at least average skills across the board. However, it failed to take the individual differences into consideration.</li> <li>For a group of people, statistics patterns might have some implications on adjustment in policies, design of teach activities. Sometimes those general implications try to satisfy most people, but actually they fit nobody. The aggregate statistics means nothing towards an individual. However, if we start from an individual pattern perspective (like IRT, CDM), it could provide more insights towards each individual. </li> <li>I agree that personality and learning varies across contexts. That’s why when we make attribution or interpretation through data, we need to be very careful about the assumptions and limitation that we might have.</li> <li>This article also raises a very interesting question - what is your value proposition of 4-year education, considering the trend of MOOCs. Some people might think it is the climate of the school, also the network or soft resources in school. From my perspective, these face-to-face things still can be done through the internet as long as we have proper platform and regulation, have something to support from a system perspective. At the end of the day, the question should be answered by individual differences - who am I? what kind of study suits me better? what do I want to be in the future? That’s why even from learning perspective, educational data should contain individual patterns, and it should be owned by students, to stimulate their awareness, ownership, engagement towards their life. The interviewee did understand this phenomena from a  relative objective perspective - business model, and he did not anti-company as well. Instead, he thinks that market needs an innovative solution in order to become a functional market.</li> <li>I am surprised to see that the interviewee also pointed out the phenomena - everyone is trying to innovate in their platform, and there is lack of interoperability standards or formate standards from a long-term sustainable development perspective. This is “a lack of appreciation that data is the thing”.</li> </ul>","","http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EIEBA2KU","journalArticle","1994","Corbett, Albert T.; Anderson, John R.","Knowledge tracing: Modeling the acquisition of procedural knowledge","User Modeling and User-Adapted Interaction","","0924-1868, 1573-1391","10.1007/BF01099821","http://link.springer.com.ezp-prod1.hul.harvard.edu/article/10.1007/BF01099821","This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called theideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels.","1994-12-01","2017-09-12 14:45:24","2017-09-12 14:45:24","2013-04-21 21:21:19","253-278","","4","4","","User Model User-Adap Inter","Knowledge tracing","","","","","","","en","","","","","link.springer.com.ezp-prod1.hul.harvard.edu","","","<ul> <li>This study made me think of the PL (parameter logistic) models in IRT, and I can’t help wondering the connections and distinctions between the two, especially the slip parameter.</li> <li>At the beginning of this article, the concepts like mastery learning, ideal student model, model tracing, declarative knowledge vs. procedural knowledge, etc.</li> <li>the learning assumptions of ACT-R are complex. the students acquire both goal-independent declarative knowledge and goal-oriented procedural rules.</li> <li>knowledge tracing assumes a two-state learning model. each coding rule is either in the learned state or in the unlearned state.</li> <li>several interpretations of slips</li> <li style=""list-style: none;""> <ul> <li>individual differences in the slip weight reflect a pure performance effect</li> <li style=""list-style: none;""> <ul> <li>may be that individual differences in the slip parameter actually reflect learning-state differences</li> </ul> </li> <li>reflects differences in the strength of underlying production rules</li> <li style=""list-style: none;""> <ul> <li>providing more practice exercises even after the student has reached the criterion learning state can improve test performance</li> </ul> </li> <li>reflect the content of the rules the student has formulated</li> <li style=""list-style: none;""> <ul> <li>it is necessary to monitor the content of students’ rules more closely</li> </ul> </li> </ul> </li> <li>goal of the research: implement a simple student modeling process that would allow the tutor to monitor the student’s knowledge state and tailor the sequence of practice exercises to the student’s needs</li> <li>simple two-state learning model enables us to estimate the student’s knowledge state from performance and predict performance from that knowledge state. successive evaluations led to:</li> <li style=""list-style: none;""> <ul> <li>abandon an initial ideal student model and to model a sufficient set of rules</li> <li>model differences in rule difficulty</li> <li>model individual differences among students in learning and performance</li> </ul> </li> <li>it may be possible to improve on the level of performance and enable more students to reach mastery by manipulating incentive in testing, by providing additional procedural practice or by monitoring and remediating students’ knowledge of key declarative concepts</li> </ul>","","","","Education (general); empirical validity; individual differences; intelligent tutoring systems; Learning; Management of Computing and Information Systems; mastery learning; Multimedia Information Systems; procedural knowledge; Psychology, general; student modeling; User Interfaces and Human Computer Interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2HEBQYSA","conferencePaper","2012","Siemens, George; Baker, Ryan S. J. d.","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Proceedings of the 2Nd International Conference on Learning Analytics and Knowledge","978-1-4503-1111-3","","10.1145/2330601.2330661","http://doi.acm.org/10.1145/2330601.2330661","Growing interest in data and analytics in education, teaching, and learning raises the priority for increased, high-quality research into the models, methods, technologies, and impact of analytics. Two research communities -- Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) have developed separately to address this need. This paper argues for increased and formal communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields.","2012","2017-09-12 14:45:24","2017-09-12 14:45:24","2015-01-16 03:15:55","252–254","","","","","","Learning Analytics and Educational Data Mining","","","","","ACM","New York, NY, USA","","","","","","ACM Digital Library","","","<p>Questions:</p> <ul> <li>Do you think EDM and LAK will become one in the future?</li> </ul> <p> </p> <p>Notes:</p> <ul> <li>Similarities <ul> <li>are defined in relatively similar ways</li> <li>both reflect the emergency of data-intensive approaches to education; both have the goal of improving the quality of analysis of large-scale educational data, to support both basic research and practice in education</li> </ul> </li> <li style=""text-align: left;"">Key Distinctions <ul> <li style=""text-align: left;""><strong>Discovery</strong>: LAK - leverage human judgement; EDM - automated discovery.</li> <li style=""text-align: left;""><strong>Adaptation &amp; Personalizatio</strong>n: LAK - informing and empowering instructors and learners; EDM - automated adaptation (by computer with no human in the loop)</li> <li style=""text-align: left;""><strong>Reduction &amp; Holism</strong>: LAK - understand systems as wholes, in their full complexity; EDM - reduce to components and analyze individual components and relationships between them</li> <li style=""text-align: left;""><strong>Origins</strong>: LAK - semantic web, ""intelligent curriculum"", outcome prediction, and systemic interventions; EDM - educational software and student modeling, predicting course outcomes</li> <li style=""text-align: left;""><strong>Technique &amp; Methods</strong>: LAK - social network analysis, sentiment analysis, influence analytics, learner success prediction, concept analysis, sensemaking models; EDM - classification, clustering, Bayesian modeling, relationship mining, discovery with models, visualization</li> </ul> </li> <li style=""text-align: left;"">collaboration allows creativity and advancement that might not otherwise occur in a single, monolithic research culture</li> <li style=""text-align: left;"">formalize approaches for dissemination of research and enacting cross-community ties; strengthen opportunities to influence non-academic research and practice</li> </ul>","","","","Collaboration; educational data mining; learning analytics and knowledge","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WQLC4B73","journalArticle","2008","Baker, Ryan S. J. d; Corbett, Albert T.; Roll, Ido; Koedinger, Kenneth R.","Developing a generalizable detector of when students game the system","User Modeling and User-Adapted Interaction","","0924-1868, 1573-1391","10.1007/s11257-007-9045-6","http://link.springer.com.ezp-prod1.hul.harvard.edu/article/10.1007/s11257-007-9045-6","Some students, when working in interactive learning environments, attempt to “game the system”, attempting to succeed in the environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly. In this paper, we present a system that can accurately detect whether a student is gaming the system, within a Cognitive Tutor mathematics curricula. Our detector also distinguishes between two distinct types of gaming which are associated with different learning outcomes. We explore this detector’s generalizability, and find that it transfers successfully to both new students and new tutor lessons.","2008-08-01","2017-09-12 14:45:25","2017-09-12 14:45:25","2015-01-16 16:33:56","287-314","","3","18","","User Model User-Adap Inter","","","","","","","","en","","","","","link.springer.com.ezp-prod1.hul.harvard.edu","","","","","http://link.springer.com.ezp-prod1.hul.harvard.edu/article/10.1007/s11257-007-9045-6","","Education (general); Management of Computing and Information Systems; Multimedia Information Systems; student modeling; User Interfaces and Human Computer Interaction; Behavior detection; Cognitive tutors; Gaming the system; Generalizable models; Interactive learning environments; Latent response models; Machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MRTYE7IL","book","2015","Zheng, Alice","Evaluating Machine Learning Models","","","","","http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page","Data science today is a lot like the Wild West: there’s endless opportunity and excitement, but also a lot of chaos and confusion. If you’re new to data science and applied machine learning, evaluating a machine-learning model can seem pretty overwhelming...","2015-09","2017-09-12 14:45:25","2017-09-12 14:45:25","2015-12-15 18:26:39","","","","","","","","","","","","O'Reily Media","Sebastopol, CA","","","","","","","","","<ul> <li>this article is very important for concluding the basic metrics</li> <li>classification metrics</li> <li style=""list-style: none;""> <ul> <li>accuracy: simply measures how often the classier makes the correct prediction (makes no distinction between classes)</li> <li>confusion matrix/table: rows (ground truth labels), columns (prediction) </li> <li>pre-class accuracy: average of the accuracy for each class (large variance when there are very few examples of one class)</li> <li>log-loss: a gauge of confidence, used when the raw output of the classifier is a numeric probability  instead of a class label of 0 or 1</li> <li>AUC (area under the curve - ROC): high is good</li> </ul> </li> <li>ranking metrics</li> <li style=""list-style: none;""> <ul> <li>precision-recall</li> <li style=""list-style: none;""> <ul> <li>precision: out of the items that the ranker/classifier predicted to be relevant, how many are truly relevant?</li> <li>recall: out of all the items that are truly relevant, how many are found by the ranker/classifier?</li> <li>look at the only top k items from the ranker: “precision@k” “recall@k”</li> </ul> </li> <li>precision-recall curve &amp; F1 score</li> <li style=""list-style: none;""> <ul> <li>precision-recall curve: plotting precision vs. recall over a range of k values. it is closely related to the ROC curve.</li> <li>F1 score: harmonic mean. small if either precision or recall is small</li> </ul> </li> <li>NDCG</li> <li style=""list-style: none;""> <ul> <li>cumulative gain (CG): sums up the relevance of the top k items</li> <li>discounted cumulative gain (DCG): discounts items that are further down the list</li> <li>normalized discounted cumulative gain (NDCG): normalized version of DCG</li> <li>DCG and NDCG are important metrics in information retrieval and in any application whiter the positioning of the returned items is important</li> </ul> </li> </ul> </li> <li>regression metrics (predict numeric scores)</li> <li style=""list-style: none;""> <ul> <li>RMSE (root mean square error, or RMSD, root mean square deviation): most commonly used metric</li> <li>Quantiles of errors: much more robust </li> <li>“Almost Correct” predictions: the percent of estimates that differ from the true value by no more than X%. the choice of X depends on the nature of the problem</li> </ul> </li> <li>caution</li> <li style=""list-style: none;""> <ul> <li>the different between training metrics and evaluation metrics: it is always better to train the model to directly optimize for the metric it will be evaluated on. always think about what is the right evaluation metric, and see if the training procedure can optimize it directly</li> <li>skewed datasets - imbalanced classes, outliers, and rare data: always be on the look out for data skew (where one kind of data is much more rare than others, or when there are very large or very small outliers that could drastically change the metric)</li> <li style=""list-style: none;""> <ul> <li>effective solutions for large outliers would probably involve careful data cleaning, and perhaps reformulating the task so that it’s not sensitive to large outliers</li> </ul> </li> </ul> </li> </ul>","","http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RKJALJJJ","blogPost","2015","Leong, B; Polonetsky, J","Why Opting Out of Student Data Collection Isn’t the Solution","EdSurge","","","","https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution","In every privacy debate across every industry, the same questions arise about the rights of individuals to “opt-out” of their data being collected or used. So it should come as no surprise that the “when” and “how” of parent and student opt-outs of education data collection or use has become a robust","2015-03-16","2017-09-12 14:45:26","2017-09-12 14:45:26","2016-01-16 16:31:25","","","","","","","","","","","","","","","","","","","","","","","","https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WTJPEGZY","videoRecording","2015","Educause","Why Is Measuring Learning So Difficult?","","","","","https://www.youtube.com/watch?v=_iv8A1pHNYA","Several higher education learning and assessment professionals discuss the difficulties of measuring learning.","2015-08-17","2017-09-12 14:45:26","2017-09-12 14:45:26","2016-01-17 18:50:57","","","","","","","","","","","","","","","","","","","YouTube","","","<p><span style=""color: #ff0000;""><em><strong>Conclusion:</strong></em></span></p> <p>1.The core reason why learning is difficult to measure comes from its controversial definition/construct. - WHAT</p> <ul> <li>Oversimplify not good, too complex not good. Need to find a point somethere in the middle</li> <li>Clarify what things(like what behaviors) happen that could indicate learning, or what specifically care about</li> </ul> <p>2.Another important reason is the difficulty to measure competencies - HOW</p> <ul> <li>Competencies and Learning are latent variables, psychological construct. hard to measure may because of the controversial definition</li> <li>Ability to assess competencies -&gt; need new technology</li> <li>Contextual - some fields tend to have weaker tools to measure and some not</li> </ul> <p>3.Measure learning is not just for diagnosis, but for revealing more possibilities to the learner - WHY</p> <p> </p> <p><em><strong>Note - Why measuring learning is difficult:</strong></em></p> <ul> <li>multi-dimensional: simplify it too much to capture the data / the understanding of the data</li> <li>learning is too board: too much, too contextual and idiosyncratic</li> <li>in some fields like computer science, have impressive tools to figure out; but in other fields especially humanities and professions we have much weaker tools for measuring learning</li> <li>learning is very personal thing: culture construct is hard to define and measure, but behaviors patterns/outputs can</li> <li>ask a wrong question - depends on what you mean by ""measure"": maybe no reliable simple proxy indicators of learning. learning is curiosity -&gt; memory; imagination -&gt; paraphrase. U word is understanding, cant's used because it is cognition word, things that we can't measure. certain kinds of things could indicate learning.</li> <li>culture and social implication, individual psychology. learning is complex and blackbox, which makes more difficult to respond to the data.</li> <li>1.ability to assess any competencies is problems. 2.Like MOOC, we don't know what people's competencies are. learning is kind of multiple measures of competence strung together that can associate with a particular experience. need to have new technologies to assess learning, people's learning at different time points.</li> <li>say what you want, measure efficiently and precisely. constructs. when talk about measure, really talking about either psychological constructs like self-efficacy or achievement.</li> <li>analytic is for the learner as well, be conscious. not to answer a question right or wrong, but reflection their learning process. analytic to reveal more possibilities for their own connected learning, not just diagnosis. be a doorway to suggest what else is possible.</li> <li>both oversimplify and too complex to understand are problems. maybe somewhere in the middle can find a good definition.</li> </ul> <p> </p>","","","","Learning; Assessment; Education; educational assessment; EDUCAUSE; Higher Education; learners; Teaching and learning","","","","","","","","","","","","","","","","","","","","","470 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"9JQZTT9N","webpage","2016","Weinersmith, Zach","Saturday Morning Breakfast Cereal","","","","","http://www.smbc-comics.com/index.php?id=3978","","2016-01-05","2017-09-12 14:45:26","2017-09-12 14:45:26","2016-01-18 18:17:09","","","","","","","","","","","","","","","","","","","","","","<ul style=""box-sizing: border-box; padding-left: 2em; text-align: start; text-indent: 0px; background-color: #ffffff; -en-clipboard: true;""> <li>This is a funny but thought-provoking comic.</li> <li><span style=""background-color: #ffffff;"">Undoubtedly, what we care (educational concept or psychological construct) plays an important role in the policy, and then education process of the students.</span></li> <li><span style=""background-color: #ffffff;"">Cause-and-effect relationship is not correlation. The direction of correction can be two sides. We should not over-interpret the statistics results.</span></li> <li><span style=""background-color: #ffffff;"">Statistics is dead until it is connected with the context, the theory etc. How we organize and interpret the data is much more important.</span></li> </ul>","","http://www.smbc-comics.com/index.php?id=3978","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V9V2E8ZN","conferencePaper","2014","Clow, Doug","Data wranglers: human interpreters to help close the feedback loop","Proceedings of the Fourth International Conference on Learning Analytics And Knowledge","","","","","","2014","2017-09-12 14:45:27","2017-09-12 14:45:27","","49–53","","","","","","","","","","","ACM","","","","","","","","","","<ul style=""box-sizing: border-box; padding-left: 2em; text-align: start; text-indent: 0px; background-color: #ffffff; -en-clipboard: true;""> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">After reading this article I started to realize and appreciate the idea that “closing the feedback loop to improve learning is at the heart of good learning analytics practice”. Human meaning-making plays an important role to support the learning analytics process.</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">In fact, I am deeply impressed by the good case practice of human Data Wranglers at the Open University, UK, because of the systematic approach they are adopting in the organization. No matter for which organization in education area, the trend of data is a huge change that impact on nearly everyone. From an organization psychology perspective, how to manage the change from a systematic approach is very important, and it can influence the actual results. That’s why I appreciate the organization practice of Open University, like ""academic staff/faculty and researchers need to be supported to learn to interpret and design learning analytics”, “establishment of a contextual framework”, “developing a culture of data use as part of increasing organizational capacity”. I am also excited to see that data wranglers “building up relationships with key stakeholders toenable the reports to focus on areas where they can be of most value” and “seek opportunities to engage withFaculty academics”. By doing this, every stakeholder can have proper communication with each other, and can “steer the agenda towards richer conceptions of learning than a naive quantitative view”, to make sure synergy can happen between learning analytics and learning design. I appreciate this systematic approach. Just like what it mentioned at the end of the paper: “present data 'to those involved in strategic institutional planning in ways that have the power to motivate organizational adoption and cultural change’”. I feel strongly inspired by this as a social-organizational psychology student.</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">They also utilize a human resource development approach to build learning analytics capacity as part of a Community of Practice, breaking the general assumption that the role of data wrangler is only to analyze the data. Additionally, all data is available to academics directly, which can stimulate their autonomy to a larger degree. The article makes it clear by presenting three scenarios clearly and concisely in the pictures.</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">Meanwhile, we also have to admit that this is a high cost approach in terms of time. </span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">Now it is an institution-wide top-down analytics strategy in place, and this is built on a bottom-up understanding of at least some of the potential of the data to improve learning. </span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">A bottom-up, grounded approach is necessary for sense making. However, as Macfadyen &amp; Dawson powerfully argue, organisational change is hard to achieve without meaningful engagement at the strategic, top-down level as well.</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">Students and teachers areclosest to the learning experience and best placed to take rapid, appropriate action in the light of learning analytics data, but managers and policymakers are able to take action at a much greater scale of impact.</span></li> </ul> </li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">Transformatory change is likely to take substantial amounts of time. It is only through the detailed processof engagement and dialogue between analysts, stakeholders andthe data that insight and organisational change are developed.</span></li> </ul> <div> </div> <div><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">other important notes:</span></div> <ul> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">A learning analytics system may be used simply to attempt toachieve set goals (single-loop learning); greater value and insight will come if those goals themselves can be interrogated, challenged, and developed (double-loop learning)</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">goals of data wrangler</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">immediate goal: producing reports with actionable recommendations</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">overall aim: drive systematic improvement through single-and double-loop learning, and through the support and development of a Community of Practice at the Open UniversityUK (OU)</span></li> </ul> </li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">data wranglers work with four main data sources: Survey feedback data; Activity data; Delivery data; Aggregated completion, pass rate and demographic data.</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">good practice</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">concerns the importance of assessment</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">students' enjoyment of different learning activities</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">data wrangler process at its best</span></li> </ul> </li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">feedback</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">positive: value the process, iterative, conversational nature; stimulate productive reflection and discussion with many stakeholders.</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">less positive: desire for more data to be included; unevenness of the process across faculties; data quality</span></li> </ul> </li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TH4GKGSM","magazineArticle","2015","Kucirkova, Natalia; FitzGerald, Elizabeth","Zuckerberg is ploughing billions into 'personalised learning' – why?","The Conversation","","","","http://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940","Zuckerburg wants to plough billions into personalised learning, but his way may not be the right way.","2015-12-09","2017-09-12 14:45:27","2017-09-12 14:45:27","2016-01-18 19:14:05","","","","","","","","","","","","","","","","","","","","","","<ul style=""box-sizing: border-box; padding-left: 2em; text-align: start; text-indent: 0px; background-color: #ffffff;""> <li>This paper offers the pros and cons of personalized learning, and the potential compromising solutions for its promising future.</li> <li>For Zuckerberg, the definition of personalized learning is about teachers “working with students to customize instruction to meet the student’s individual needs and interests”. the underlying principles are the similar with how Facebook’s news feed works: human work is replaced by technology, algorithms provide users with context based on analysis of their past behavior and demonstrated interested.</li> <li>The author thought there were three major flaws of that</li> <li style=""list-style: none;""> <ul> <li>generable knowledge and skills are also important, but they are ignored in personalized learning</li> <li>the real world life will not be always accommodating and students need the ability to compensate</li> <li>children’s preferences often change as immediate responses to the environment, and valuable social contact between students, teachers and parents are important</li> <li>it also poses a privacy risk if it is not managed properly</li> </ul> </li> <li>personalized learning could help a lot in the motivation, which is crucial for effective learning. we can combine user data with standard educational content.</li> </ul>","","https://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8DSI49RK","videoRecording","2015","Georgia Tech","Feature Selection","","","","","https://www.youtube.com/watch?v=8CpRLplmdqE","","2015-02-23","2017-09-12 14:45:27","2017-09-12 14:45:27","2016-01-18 19:18:06","","","","","","","","","","","","Youtube","","","","","","","","","","<div>feature selection</div> <div> <ul> <li>knowledge discovery (human being)</li> <li style=""list-style: none;""> <ul> <li>interpretability for insights</li> <li>should not be ignored!</li> </ul> </li> </ul> </div> <div> <ul> <li>curse of dimensionality (machines and machine learning algorithms)</li> <li style=""list-style: none;""> <ul> <li>the amount of data you need grows exponentially in the number of features that you have.</li> <li>reduce the number of features hopefully, to make learning problems easier</li> <li>the goal is to be able to use a bunch of features, and then by applying some of the algorithms to get to just the important features -&gt; understand data better + have easier learning problems</li> </ul> </li> </ul> </div>","","https://www.youtube.com/watch?v=8CpRLplmdqE","","","","","","","","","","","","","","","Udacity","","","","","","","","3:13","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6GIIRSY","bookSection","2016","Hanneman, R.A.; Riddle, M.","Chapter 1: Social Network Data","Introduction to Social Network Methods","","","","http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html","","2016-01-18","2017-09-12 14:45:27","2017-09-12 14:45:27","2016-01-18 20:17:24","","","","","","","","","","","","","","","","","","","","","","<div> <ul> <li>This article also introduces basic statistical measures/concepts of social network. It emphasized the dependent characteristics of social network data as well. It is great that it compare the scales of measure of network with conventional data, which is very clear.</li> <li>network data is a special form of conventional data, but actors are described by their relations, not by their attributes. nodes (actors); edges (relations).</li> <li>network designs can be described as nested designs / hierarchical designs</li> <li>usually identify some population and conduct a census (include all elements of the population as unites of observation)</li> <li style=""list-style: none;""> <ul> <li>two types of boundaries of the populations: boundaries that already known (priori) vs. more demographic/ecological approach to define the boundaries</li> <li>expand the boundaries by replicating populations: expand the scope vs. inclusion of multiple levels of analysis / modalities</li> </ul> </li> <li>sampling ties</li> <li style=""list-style: none;""> <ul> <li>full network methods: collect information about each actor’s ties with all other actors</li> <li style=""list-style: none;""> <ul> <li>maximum of information; costly and difficult to execute, difficult to generalize</li> </ul> </li> <li>methods that like conventional survey research: less information about network struc<span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">ture, less costly, easier generalization.</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">snowball methods </span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">continues until no new actors are identified, or until we decide to stop (usually for reasons of time andresources, or because the new actors being named are very marginal to the group we are tryingto study).</span></li> <li><span style=""font-family: 'Helvetica Neue';"">particularly helpful for tracking down ""special” populations</span></li> <li><span style=""font-family: 'Helvetica Neue';"">limitations: actors who are not connected are not located; no guaranteed way o findings all of the connected individuals in the population</span></li> </ul> </li> <li><span style=""font-family: 'Helvetica Neue';"">ego-centric networks (with alter connections)</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue';"">begin with a selection of focal nodes (egos), identify the nodes to which they are connected</span></li> <li><span style=""font-size: 16pt; font-family: ArialMT;"">effective for collecting a form of relational data from verylarge populations, and can be combined with attribute-based approaches</span></li> </ul> </li> <li><span style=""font-family: 'Helvetica Neue';"">ego-centric networks (ego only)</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue';"">focus on the individual, rather than on the network as a whole</span></li> <li><span style=""font-family: 'Helvetica Neue';"">understand how networks affect individuals, give a incomplete picture of the general texture of the network as a whole</span></li> </ul> </li> </ul> </li> </ul> </li> <li><span style=""font-family: 'Helvetica Neue';"">if don’t know what relations to examine, can use systems theory to decide</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue';"">material domain: “conserved” in the sense that they can only be located at one node of the network at a time</span></li> <li><span style=""font-family: 'Helvetica Neue';"">informational domain: “non-conserved” in the sense that they can be in more than one place at the same time</span></li> <li><span style=""font-family: 'Helvetica Neue';"">simple possession of a common attribute (e.g. gender) vs. the presence of a tie (e.g. the exchange of views between two persons on issues of gender)</span></li> </ul> </li> <li><span style=""font-family: 'Helvetica Neue';"">scales of measurement</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue';"">binary measures</span></li> <li><span style=""font-family: 'Helvetica Neue';"">multiple-category nominal measures </span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue';"">nominal or quantitative, each person’s relationship to the subject is coded by its type, rather than its strength. similar to “dummy coding""</span></li> </ul> </li> <li><span style=""font-family: 'Helvetica Neue';"">grouped ordinal measures</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue';"">coded -1, 0, 1 to reflect negative liking, indifference, and positive liking</span></li> <li><span style=""font-family: 'Helvetica Neue';"">“strength”: frequency of interaction</span></li> <li><span style=""font-family: 'Helvetica Neue';"">“intensity”: the degree of emotional arousal associated with the relationship</span></li> <li><span style=""font-family: 'Helvetica Neue';"">ties can be strong if involving many different contexts or types of ties; or reciprocated</span></li> </ul> </li> <li><span style=""font-family: 'Helvetica Neue';"">full-rank ordinal measures</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue';"">score the strength of all of the relations of an actor in a rank order from strongest to weakest</span></li> <li><span style=""font-family: 'Helvetica Neue';"">such scales reflect differences in degree of intensity, but not necessarily equal differences</span></li> <li><span style=""font-family: 'Helvetica Neue';"">usually it will be treated as if they were interval</span></li> </ul> </li> <li><span style=""font-family: 'Helvetica Neue';"">interval measures (most advanced level of measurement</span><span style=""font-family: 'Helvetica Neue';"">)</span></li> </ul> </li> <li><span style=""font-family: 'Helvetica Neue';"">mathematical approaches to network analysis tend to treat the data as deterministic.</span></li> <li><span style=""font-family: 'Helvetica Neue';"">statistical analysts tend to regard the particular scores on relationship strengths as stochastic or probabilistic realizations of an underlying true tendency or probability distribution of relationship strengths</span></li> <li><span style=""font-family: 'Helvetica Neue';"">differences of social network data: not probability samples; not independent. -&gt; these differences might bring questions of generalization of findings, and for mechanics of hypothesis testing.</span></li> </ul> </div>","","http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSV6DW8Q","webpage","2014","Groelmund, Garrett","RStudio Cheat Sheets","RStudio","","","","https://www.rstudio.com/resources/cheatsheets/","","2014-08-01","2017-09-12 14:45:28","2017-09-12 14:45:28","2016-01-19 21:17:28","","","","","","","","","","","","","","","","","","","","","","<ul> <li>workflow: open a new .Rmd file -&gt; write document -&gt; knit document to create report -&gt; preview output -&gt; publish -&gt; examine build log -&gt; use output file</li> <li><span style=""background-color: #ffffff;"">embed code with knit syntax: inline code, code chunks, global options</span></li> <li><span style=""background-color: #ffffff;"">parameters: </span></li> <li style=""list-style: none;""> <ul> <li><span style=""background-color: #ffffff;"">add parameters: params</span></li> <li><span style=""background-color: #ffffff;"">call parameters: param$&lt;name&gt;</span></li> <li><span style=""background-color: #ffffff;"">set parameters: knit with parameters / render()</span></li> </ul> </li> <li><span style=""background-color: #ffffff;"">Pandora’s Markdown: check the cheatsheet. a useful way to edit the document</span></li> <li><span style=""background-color: #ffffff;"">Set render options with YAML: very confused… will work on it very soon.</span></li> <li><span style=""background-color: #ffffff;"">create a reusable template</span></li> <li style=""list-style: none;""> <ul> <li><span style=""background-color: #ffffff;"">create a new package with a inst/rmarkdown/teamplates directory</span></li> <li><span style=""background-color: #ffffff;"">in the directory, place a folder that contains</span></li> <li style=""list-style: none;""> <ul> <li><span style=""background-color: #ffffff;"">`template.yaml</span></li> <li><span style=""background-color: #ffffff;"">skeleton.Rmd</span></li> <li><span style=""background-color: #ffffff;"">any supporting files</span></li> </ul> </li> <li><span style=""background-color: #ffffff;"">install the package</span></li> <li><span style=""background-color: #ffffff;"">access template in wizard at File -&gt; New File -&gt; R Markdown</span></li> </ul> </li> <li><span style=""background-color: #ffffff;"">table suggestions: </span></li> <li style=""list-style: none;""> <ul> <li><span style=""background-color: #ffffff;"">knit::kable()</span></li> <li><span style=""background-color: #ffffff;"">print(xtable::xtable(),type=“html”,html.table.attributes=“border=0”))</span></li> <li><span style=""background-color: #ffffff;"">stargazer::stargazer(data,type=“html”,title=“table with stargazer”)</span></li> </ul> </li> <li><span style=""background-color: #ffffff;"">citations and bibliographies: </span></li> <li style=""list-style: none;""> <ul> <li><span style=""background-color: #ffffff;"">set bibliography file</span></li> <li><span style=""background-color: #ffffff;"">use citation keys in tex</span></li> <li><span style=""background-color: #ffffff;"">render</span></li> </ul> </li> </ul>","","http://shiny.rstudio.com/articles/rm-cheatsheet.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FDEFQWLI","conferencePaper","2013","san Pedro, Maria Ofelia; Baker, Ryan; Bowers, Alex; Heffernan, Neil","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","Educational Data Mining 2013","","","","","","2013","2017-09-12 14:45:28","2017-09-12 14:45:28","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QPVFB9W4","journalArticle","2012","Greller, Wolfgang; Drachsler, Hendrik","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Journal of Educational Technology & Society","","1176-3647","","http://www.jstor.org/stable/jeductechsoci.15.3.42","ABSTRACT With the increase in available educational data, it is expected that Learning Analytics will become a powerful means to inform and support learners, teachers and their institutions in better understanding and predicting personal learning needs and performance. However, the processes and requirements behind the beneficial application of Learning and Knowledge Analytics as well as the consequences for learning and teaching are still far from being understood. In this paper, we explore the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. We propose and discuss a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency. Furthermore, the presented article intends to inform about soft barriers and limitations of Learning Analytics. We identify the required skills and competences that make meaningful use of Learning Analytics data possible to overcome gaps in interpretation literacy among educational stakeholders. We also discuss privacy and ethical issues and suggest ways in which these issues can be addressed through policy guidelines and best practice examples.","2012","2017-09-12 14:45:28","2017-09-12 14:45:28","2016-09-03 18:55:41","42-57","","3","15","","Journal of Educational Technology & Society","Translating Learning into Numbers","","","","","","","","","","","","JSTOR","","","<ul> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">Thanks to this generic framework, I have a general understanding towards learning analytics. The framework contains both technically-focused research questions and softer issues and problem areas. There are six critical dimensions of LA, including stakeholders, objectives, data, instruments, external constrains, internal limitation. It is very impressive that the generic framework also includes soft issues - challenges that depend on assumptions being made about humans or the society in general.</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">The framework can be used as a checklist when designing a purposeful LA process; or as a sharable description framework to compare context parameters with other similar approaches in other contexts. I agree that the framework is more like “both a descriptive approach as well as a guide to the design process of LA applications”, and that “development should not happen without a guiding framework that combines use of educational data with theprotection of individuals and their learning.”. Personally for me, this is more like a standardized process and materials, and it is qualitative instead of quantitative. We are not sure how the inherent connections among the six dimensions are connected. The general preference of this article is more soft issues focused, and less technically-focused.</span></li> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">I am most impressed by the assumption of this framework - “responsible designers of analytic processes will not only implement what is technically possible to do and legally allowed (or at least not prohibited), but to</span> <span style=""background-color: #ffffff; font-family: 'Helvetica Neue'; font-size: 14px; font-style: italic; text-decoration: underline;"">consider holistically the outcomes for stakeholders and, even more importantly, the consequences for the data subjects.</span><span style=""background-color: #ffffff; font-family: 'Helvetica Neue'; font-size: 14px;"">”</span></li> <li><span style=""background-color: #ffffff; font-family: 'Helvetica Neue'; font-size: 14px;"">Other insights that I’ve got are</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: 'Helvetica Neue'; font-size: 14px;"">I never thought of this perspective until seeing this article - ""by comparison, still seem somewhat bizarre that in the commercial worldwith clicking the “register” button, the default access to all user data becomes owned by some company, whereas educational institutions operate on the default that everything is protected from virtually everyone.”</span></li> <li><span style=""background-color: #ffffff; font-family: 'Helvetica Neue'; font-size: 14px;"">“Using statistical analytic findings is a quantitative not a qualitative support agent to such decision making.” “aligning and regulating performance and behaviour of individual teachers or learners against a statisticalnorm without investigating the reasons for their divergence may strongly stifle innovation, individuality, creativityand experimentation""</span></li> <li><span style=""background-color: #ffffff; font-family: 'Helvetica Neue'; font-size: 14px;"">“From a technical point of view, idealised datasets probably remain the biggest challenge for analytics” “users ‘pollute' databases by producing erroneous or incomplete datasets.""</span></li> <li><span style=""background-color: #ffffff; font-family: 'Helvetica Neue'; font-size: 14px;"">“High drop-out rates are a challenging problem in education, especially distance education.""</span></li> <li><span style=""background-color: #ffffff; font-family: 'Helvetica Neue'; font-size: 14px;"">“Competing methods, technologies and algorithms applied to the same set of data, will result in different outcomes, and thus may lead to different consequences in terms of decision making based on these outcomes.""</span></li> <li><span style=""background-color: #ffffff; font-family: 'Helvetica Neue'; font-size: 14px;"">""The fundamental question legislators need to ask is: who does a person’s lifedata belong to?"" ""the extent of a student’s data contract with an institution and its individual staff representatives indifferent roles (teacher, administrator, secretary, researcher, IT support staff, Deans and management, etc.) needs to be urgently clarified.""</span></li> </ul> </li> <li><span style=""background-color: #ffffff; font-family: 'Helvetica Neue'; font-size: 14px;"">“data economy” is a current trend and it made colle</span><span style=""background-color: #ffffff;"">cting data an affordable activity, and it can reflect real and un interrupted user behavior.</span></li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YRUVGSFB","bookSection","2006","Kay, Judy; Maisonneuve, Nicolas; Yacef, Kalina; Reimann, Peter","The Big Five and Visualisations of Team Work Activity","Intelligent Tutoring Systems","978-3-540-35159-7 978-3-540-35160-3","","","http://link.springer.com/chapter/10.1007/11774303_20","We have created a set of novel visualisations of group activity: they mirror activity of individuals and their interactions, based upon readily available authentic data. We evaluated these visualisations in the context of a semester long software development project course. We give a theoretical analysis of the design of our visualizations using the framework from the “Big 5” theory of team work as well as a qualitative study of the visualisations and the students’ reflective reports. We conclude that these visualisations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness.","2006-06-26","2017-09-12 14:45:28","2017-09-12 14:45:28","2016-09-03 19:10:12","197-206","","","","","","","","","","","Springer Berlin Heidelberg","","en","©2006 Springer-Verlag Berlin Heidelberg","","","","link.springer.com","","","","","https://link.springer.com/chapter/10.1007/11774303_20","","Multimedia Information Systems; User Interfaces and Human Computer Interaction; Artificial Intelligence (incl. Robotics); Computers and Education; Information Systems Applications (incl. Internet)","Ikeda, Mitsuru; Ashley, Kevin D.; Chan, Tak-Wai","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XM7SQWS7","journalArticle","2015","Konstan, Joseph A.; Walker, J. D.; Brooks, D. Christopher; Brown, Keith; Ekstrand, Michael D.","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","ACM Trans. Comput.-Hum. Interact.","","1073-0516","10.1145/2728171","http://doi.acm.org/10.1145/2728171","","2015-04","2017-09-12 14:45:28","2017-09-12 14:45:28","2016-09-03 20:38:02","10:1–10:23","","2","22","","","Teaching Recommender Systems at Large Scale","","","","","","","","","","","","ACM Digital Library","","","<ul style=""box-sizing: border-box; padding-left: 2em; text-align: start; text-indent: 0px; background-color: #ffffff;""> <li>I love the research goals of this paper. They are very interesting and relevant, especially considering the application of MOOC in life, and how are the effects comparing with traditional face-to-face courses’ effects. The six research goals not only provide the teaching recommendations, but also they imply the trend of the education in the future.</li> <li>However, this article is a little bit boring for me. It might because the simple statistics methods, heavy design and performance measure details, and more importantly, it might not be my particular interest field.</li> <li>I will just mark down some key results:</li> <li style=""list-style: none;""> <ul> <li>intention predicts completion; little else does.</li> <li>student knowledge increased</li> <li>face-to-face students learned at least as much as online-only students</li> <li>students at all incoming knowledge levels benefited similarly from the course</li> <li>students in the programming and concepts tracks had similar gains in concepts knowledge, but programming students gained further knowledge</li> <li>normalized knowledge gains are very difficult to predict; measures of relevant effort were strongest</li> <li>predicting student end-of-term performance is difficult; appropriate predictor variables may be lacking</li> </ul> </li> </ul> <div> </div>","","","","learning assessment; Massively Online Open Course (MOOC)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S8XKC5AY","bookSection","2013","Desmarais, Michel C.; Naceur, Rhouma","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Artificial Intelligence in Education","978-3-642-39111-8 978-3-642-39112-5","","","http://link.springer.com/chapter/10.1007/978-3-642-39112-5_45","Uncovering the right skills behind question items is a difficult task. It requires a thorough understanding of the subject matter and of the cognitive factors that determine student performance. The skills definition, and the mapping of item to skills, require the involvement of experts. We investigate means to assist experts for this task by using a data driven, matrix factorization approach. The two mappings of items to skills, the expert on one side and the matrix factorization on the other, are compared in terms of discrepancies, and in terms of their performance when used in a linear model of skills assessment and item outcome prediction. Visual analysis shows a relatively similar pattern between the expert and the factorized mappings, although differences arise. The prediction comparison shows the factorization approach performs slightly better than the original expert Q-matrix, giving supporting evidence to the belief that the factorization mapping is valid. Implications for the use of the factorization to design better item to skills mapping are discussed.","2013-07-09","2017-09-12 14:45:28","2017-09-12 14:45:28","2016-09-03 20:44:11","441-450","","","","","","","","","","","Springer Berlin Heidelberg","","en","©2013 Springer-Verlag Berlin Heidelberg","","","","link.springer.com","","","","","https://link.springer.com/chapter/10.1007/978-3-642-39112-5_45","","User Interfaces and Human Computer Interaction; Artificial Intelligence (incl. Robotics); Computers and Education; Information Systems Applications (incl. Internet); alternating least squares matrix factorization; Cognitive modeling; Educational Technology; latent skills; Pedagogic Psychology; skills assessment; Student models","Lane, H. Chad; Yacef, Kalina; Mostow, Jack; Pavlik, Philip","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ALU94SW6","book","2015","Matsuda, Noboru; Furukawa, Tadanobu; Bier, Norman; Faloutsos, Christos","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","","","","","http://eric.ed.gov/?id=ED560513","How can we automatically determine which skills must be mastered for the successful completion of an online course? Large-scale online courses (e.g., MOOCs) often contain a broad range of contents frequently intended to be a semester's worth of materials; this breadth often makes it difficult to articulate an accurate set of skills and knowledge (i.e., a skill model, or the QMatrix). We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability. [For complete proceedings, see ED560503.]","2015-06","2017-09-12 14:45:29","2017-09-12 14:45:29","2016-09-03 20:48:57","","","","","","","Machine Beats Experts","","","","","International Educational Data Mining Society","","en","","","","","ERIC","","","<ul style=""box-sizing: border-box; padding-left: 2em; text-align: start; text-indent: 0px; background-color: #ffffff;""> <li>The eEPHIPHANY proposed in this article is really fantastic. It provides a new method to refine the skills for me (previously I did test refinement with the combination of LFA and human experts, that is, using expert to define and revise the Q-matrix in CDM). eEPIPHANY has high accuracy and requires low human labor, and it is very impressive.</li> <li>Their core goal is to provide evidence-based feedback for online course refinement (clear educational goal). Transfer to eEPIPHANY method, technically, their goal is to find a skill model (Q-matrix) that produces the best prediction of the A-matrix. The predictive power is measured by cross-validation</li> <li>feature extraction: clustering assessment items with latent features that would best characterize  the similarity in the difficulties of assessment items</li> <li style=""list-style: none;""> <ul> <li>Matrix factorization (MF) strategy: check the paper for more detailed information. it is very great.</li> <li>Bag-of-words (BoW) strategy: create the F-matrix directly from a collection of item stems for assessment items.</li> </ul> </li> <li>skill model construction: proposing a new skill model by assuming that the above-mentioned cluster of assessment items provides a hint for new skills</li> <li style=""list-style: none;""> <ul> <li>Replace strategy: the P-matrix is straightforwardly converted into the Q-matrix</li> <li>Append strategy adds more skill-item associations to the default skill model, while the original skill-item associations in the default skill model remain intact</li> <li>Split strategy: individually splitting skill-item associations into multiple new skill-item associations</li> </ul> </li> <li>model search: searching for the best skill model by comparing multiple skill model candidates</li> <li>model interpretation: the DoE (degree of enhancement) analysis</li> <li>results: MF strategy always outperformed BoW strategy. when MF strategy is used, replacing the default skill model with completely new skill model discovered by eEPIPHANY yielded the best skill model, while split strategy always resulted in producing inferior skill model (suggesting that the split strategy hardly improves on the human-crafted skill).</li> </ul>","","http://eric.ed.gov/?id=ED560513","","data; Automation; Comparative Analysis; Correlation; Formative Evaluation; models; Online Courses; Skills","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2PTGPYK","conferencePaper","2008","Cortez, Paulo; Silva, Alice Maria Gonçalves","Using data mining to predict secondary school student performance","Proceedings of 5th Annual Future Business Technology Conference","978-90-77381-39-7","","","http://repositorium.sdum.uminho.pt/handle/1822/8024","Although the educational level of the Portuguese population has improved in the last decades, the statistics keep Portugal at Europe’s tail end due to its high student failure rates. In particular, lack of success in the core classes of Mathematics and the Portuguese language is extremely serious. On the other hand, the fields of Business Intelligence (BI)/Data Mining (DM), which aim at extracting high-level knowledge from raw data, offer interesting automated tools that can aid the education domain. The present work intends to approach student achievement in secondary education using BI/DM techniques. Recent real-world data (e.g. student grades, demographic, social and school related features) was collected by using school reports and questionnaires. The two core classes (i.e. Mathematics and Portuguese) were modeled under binary/five-level classification and regression tasks. Also, four DM models (i.e. Decision Trees, Random Forest, Neural Networks and Support Vector Machines) and three input selections (e.g. with and without previous grades) were tested. The results show that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available. Although student achievement is highly influenced by past evaluations, an explanatory analysis has shown that there are also other relevant features (e.g. number of absences, parent’s job and education, alcohol consumption). As a direct outcome of this research, more efficient student prediction tools can be be developed, improving the quality of education and enhancing school resource management.","2008-04","2017-09-12 14:45:29","2017-09-12 14:45:29","2016-09-04 01:23:19","","","","","","","","","","","","EUROSIS","Porto, Spain","eng","openAccess","","","","repositorium.sdum.uminho.pt","","","","","http://repositorium.sdum.uminho.pt/handle/1822/8024","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","5th Annual Future Business Technology Conference","","","","","","","","","","","","","","",""
"R5FIFSHE","book","2014","Baker, R","Big Data in Education","","","","","","","2014","2017-09-12 14:45:30","2017-09-12 14:45:30","","","","","","","","","","","","","","New York, NY","","","","","","","","","<p>Chapter 1 Video 1</p> <p> </p> <ul> <li>This course mainly introduces EDM/LAK. The whole idea is that EDM/LAK is great!</li> <li>Well, it talks about the methods, background, application, contents in this class with regard to EDM/LAK.</li> <li>Here are the most useful things: types of EDM/LA method</li> <li style=""list-style: none;""> <ul> <li>prediction: develop a model which can infer a single aspect of the data (predicted variable) from some combination of other aspects of the data (predictor variables)</li> <li style=""list-style: none;""> <ul> <li>classification</li> <li>regression</li> <li>later knowledge estimation</li> </ul> </li> <li>structure discovery: find structure and patterns in the data that emerge “naturally”; no specific target or predictor variable</li> <li style=""list-style: none;""> <ul> <li>clustering</li> <li>factor analysis</li> <li>domain structure discovery</li> <li>network analysis</li> </ul> </li> <li>relationship mining: discover relationships between variables in a data set with many variables</li> <li style=""list-style: none;""> <ul> <li>association rule mining</li> <li>correlation mining</li> <li>sequential pattern mining</li> <li>causal data mining</li> </ul> </li> <li>distillation of data for human judgment</li> <li>discovery with models: pre-existing model; applied to data and used as a component in another analysis</li> </ul> </li> <li>Closing thoughts</li> <li style=""list-style: none;""> <ul> <li> EDM/LAK methods emerging for big data in education</li> <li style=""list-style: none;""> <ul> <li>we will learn key methods and use them for</li> <li style=""list-style: none;""> <ul> <li>promoting scientific discovery</li> <li>driving intervention and improvements in educational software and systems</li> </ul> </li> <li>strengths and weaknesses of methods for different applications</li> <li>is your analysis trustworthy? is it applicable?</li> </ul> </li> </ul> </li> </ul>; <p>Chapter 2 Video 2 &amp; 3 &amp; 4</p> <p> </p> <ul style=""box-sizing: border-box; padding-left: 2em; text-align: start; text-indent: 0px; background-color: #ffffff;""> <li>metrics for classifiers</li> <li style=""list-style: none;""> <ul> <li>accuracy / agreement (when measuring inter-rater reliability)</li> <li style=""list-style: none;""> <ul> <li>accuracy does poorly when there is non-even assignment to categories, which is almost always the case</li> </ul> </li> <li>kappa (learn how to compute kappa in a 2x2 example)</li> <li style=""list-style: none;""> <ul> <li>kappa = 0: agreement is at chance</li> <li>kappa = 1: agreement is perfect</li> <li>kappa = -1: agreement is perfectly inverse</li> <li>kappa &gt;1: you messed up somewhere</li> <li>kappa &lt;0: your model is worse than chance. seen more commonly if you are using cross-validation (it means your model is junk)</li> <li>0&lt;kappa&lt;1: there is no absolute standard for a good kappa</li> <li style=""list-style: none;""> <ul> <li>why is there no standard? because kappa is scaled by the proportion of each category. when one class is much more prevalent, expected agreement is higher than classes are evenly balanced.</li> <li>because of this, comparing kappa values between two data sets, in a principled fashion, is highly difficult. it is okay to compare Kappa values within a dataset.</li> <li>informally, can compare two data sets if the proportions of each category are “similar""</li> </ul> </li> </ul> </li> <li>ROC (receiver-operating characteristics curve)</li> <li style=""list-style: none;""> <ul> <li>predicting something which has two values</li> <li>prediction model outputs a probability or other real value</li> <li>four possibilities: TP, FP, TN, FN</li> <li>ROC curve</li> </ul> </li> <li>A’ (A prime, a close relative of ROC)</li> <li style=""list-style: none;""> <ul> <li>the probability that if the model is given an example from each category, it will accurately identify which is which</li> <li>is mathematically equivalent to the Wilcoxon statistics </li> <li>useful result, because it means that you can compute statistical tests for</li> <li style=""list-style: none;""> <ul> <li>whether two A’ values are significantly different (same data set or different data sets)</li> <li>whether an A’ value is significant different than chance</li> </ul> </li> <li>not really a good way (yet) to compute A’ for 3 or more categories</li> <li>this test assumes independence. </li> <li>closely mathematically approximates the area under the ROC curve, called AUC</li> <li>caution: the implementation of AUC are buggy in all major statistical packages that I’ve looked at. special cases get messed up.</li> </ul> </li> <li>A’ and Kappa</li> <li style=""list-style: none;""> <ul> <li>A’: more difficult to compute; only works for two categories (without complicated extensions); meaning is invariant across data sets (A’=0.6 is always better than A’=0.55); very easy to interpret statistically</li> <li>A’ values are almost always higher than Kappa values</li> <li>A’ takes confidence into account</li> </ul> </li> <li>precision and recall</li> <li style=""list-style: none;""> <ul> <li>precision = the probability that a data point classified as true is actually truer</li> <li>recall = the probability that a data point that is actually true is classified as true</li> </ul> </li> <li>still active debate about these metrics</li> <li style=""list-style: none;""> <ul> <li>A’ is more robust to skewed distributions than Kappa and also several other metrics</li> <li>models selected with RMSE come close to true parameter values than A'</li> </ul> </li> </ul> </li> <li>metrics for regressor</li> <li style=""list-style: none;""> <ul> <li>linear correlation</li> <li style=""list-style: none;""> <ul> <li>same correlation, different functions</li> <li>look at scatter</li> <li>why are small correlations OK in education? lots and lots of factors contribute to just about any dependent measure</li> </ul> </li> <li>r square</li> <li style=""list-style: none;""> <ul> <li>the correlation, squared</li> <li>a measure of what percentage of variance in dependent measure is explained by a model</li> <li>r square is often used as the measure of model goodness rather than r (depends on teh community)</li> </ul> </li> <li>RMSE (root mean squared error ) / MAD (mean absolute deviation)</li> <li style=""list-style: none;""> <ul> <li>MAD</li> <li style=""list-style: none;""> <ul> <li>average of </li> <li>absolute value (actual value minus predicted value)</li> </ul> </li> <li>RMSE</li> <li style=""list-style: none;""> <ul> <li>square root of average of </li> <li>(actual value minus predicted value) square</li> </ul> </li> <li>MAD vs. RMSE</li> <li style=""list-style: none;""> <ul> <li>MAD tells you the average amount to which the predictions deviate from teh actual values: very interpretable</li> <li>RMSE can be interpreted the same way (mostly) but penalizes large deviation more than small deviation</li> </ul> </li> </ul> </li> <li>Good model = low RMSE/MAD, high correlation</li> <li style=""list-style: none;""> <ul> <li>low RMSE/MAD is good</li> <li>high correlation is good</li> <li>high RMSE/MAD, high correlation = model goes in the right direction, but is systematically biased</li> <li>low RMSE/MAD, low correlation = model values are in the right range, but model doesn’t capture relative change (particularly common if there is not much variation in data)</li> </ul> </li> </ul> </li> <li>information criteria</li> <li style=""list-style: none;""> <ul> <li>BiC</li> <li style=""list-style: none;""> <ul> <li>Bayesian Information Criterion</li> <li>makes the trade-off between goodness of fit and flexibility of fit (number of parameters)</li> <li>values over 0: worse than expected given number of variables</li> <li>values under 0: better than expected given number of variables</li> <li>can be used to understand significance of difference between models</li> <li>said to be statistically equivalent to k-fold cross-validation for optimal k</li> <li>BiC is easier to compute than cross-validation, but different formulas must be used for different modeling frameworks. no BiC formula available for many modeling frameworks</li> </ul> </li> <li>AIC</li> <li style=""list-style: none;""> <ul> <li>alternative to BiC</li> <li>stands for: an information criterion / akaike’s information criterion</li> <li>makes slightly different trade-off between goodness of fit and flexibility of fit (number of parameters)</li> <li>said to be statistically equivalent to leave-out-one-cross-validation</li> </ul> </li> <li>AIC or BIC: which one should you use?</li> <li style=""list-style: none;""> <ul> <li>“the idea of looking for a single best measure to choose between classifiers is wrongheaded.""</li> </ul> </li> </ul> </li> </ul>; <p>Chapter 2 Video 5</p> <p> </p> <ul> <li>over-fitting</li> <li style=""list-style: none;""> <ul> <li>fit the noise as well as the signals</li> <li>reduce over-fitting</li> <li style=""list-style: none;""> <ul> <li>use simpler models: fewer variables (BiC, AIC, Occam’s Razor); less complex functions (MDL)</li> </ul> </li> <li>eliminate over-fitting?</li> <li style=""list-style: none;""> <ul> <li>every model is overfit in some fashion</li> <li>the questions are: how bad? what is it over-fit to?</li> </ul> </li> <li>assess generalizability</li> <li style=""list-style: none;""> <ul> <li>does your model transfer to new contexts?</li> <li>or is it overfit to a specific context?</li> <li>training set/test set</li> <li>model tested on unseen data, but uses data unevenly</li> </ul> </li> </ul> </li> <li>cross-validation</li> <li style=""list-style: none;""> <ul> <li>split data points into N equal-size groups</li> <li>train on all groups but one, test on last group</li> <li>for each possible combination</li> <li>how many groups?</li> <li style=""list-style: none;""> <ul> <li>K-fold: pick a number K, split into this number of groups</li> <li style=""list-style: none;""> <ul> <li>quicker; preferred by some theoreticians</li> </ul> </li> <li>leave-out-one: every data point is a fold</li> <li style=""list-style: none;""> <ul> <li>avoid issue of how to select folds (stratification issues)</li> </ul> </li> </ul> </li> <li>cross-validation variants</li> <li style=""list-style: none;""> <ul> <li>flat cross-validation</li> <li style=""list-style: none;""> <ul> <li>each point has equal chance of being placed into each fold</li> </ul> </li> <li>stratified cross-validation</li> <li style=""list-style: none;""> <ul> <li>biases fold selection so that some variable is equally represented in each fold</li> <li>the variable you’re trying to predict</li> <li>or some variable that is thought to be an important context</li> </ul> </li> <li>student-level cross-validation</li> <li style=""list-style: none;""> <ul> <li>folds are selected so that no student’s data is represented in two folds</li> <li>allows you to test model generalizability to new students</li> <li>as opposed to testing model generalizability to new data from the same students</li> <li>usually seen as the minimum cross-validation needed, in the EDM conference</li> <li>papers that don’t pay attention to this issue are usually rejected</li> <li>easy to do with Batch X-Validation in RapidMiner</li> </ul> </li> </ul> </li> <li>other levels sometimes used for cross-validation: lesson/content, school, demographic (urban/rural/suburban/race/gender), software package</li> <li>important consideration</li> <li style=""list-style: none;""> <ul> <li>where do you want to be able to use your model?</li> <li>make sure to cross-validate at that level</li> </ul> </li> </ul> </li> </ul>; <div style=""-en-clipboard: true;"">Chapter 7 Video 1 &amp; 2</div> <div style=""-en-clipboard: true;""> </div> <div style=""-en-clipboard: true;"">video 1 - clustering</div> <ul> <li>the biggest takeaway from this video is to understand how k-means clustering algorithm work through different examples</li> <li>clustering: have a large number of data points; want to find what structure there is among the data points; don’t know anything a priori about the structure. clustering tries to find data points that “group together”</li> <li>clustering works for (and is effective in) large features spaces</li> <li>k-means clustering algorithm is the simplest one</li> <li style=""list-style: none;""> <ul> <li>first, decide how many clusters we wanted</li> <li>pick starting values for the “centroids” of the clusters</li> <li style=""list-style: none;""> <ul> <li>usually chosen randomly</li> <li>sometimes there are good reasons to start with specific initial values, like insights from old data set</li> </ul> </li> <li>classify every point as to which centroid it’s closest to</li> <li style=""list-style: none;""> <ul> <li>this defines the clusters</li> <li>typically visualized as a voronoi diagram</li> </ul> </li> <li>refit the centroids as the center of the points in each cluster</li> <li>repeat the process until the centroids stop moving</li> <li>“converge"" - no points switched</li> </ul> </li> <li>outliers. starting points might be in a strong place. (cluster might be empty as well)</li> <li style=""list-style: none;""> <ul> <li>one solution: run several times, including different </li> </ul> </li> <li>a lot depends on initial positioning and on the number of clusters</li> </ul> <div> </div> <div>video 2 - Validation and Selection of K</div> <ul> <li>distortion / mean squared deviation </li> <li style=""list-style: none;""> <ul> <li>steps</li> <li style=""list-style: none;""> <ul> <li>take each point P</li> <li>find the centroids of P’s cluster C</li> <li>find the distance D from C to P</li> <li>square D to get D’</li> <li>sum all D’ to get Distortion</li> </ul> </li> <li>works for choosing between randomized restarts</li> <li>not works for choosing cluster size, because more clusters almost always leads to smaller distortion</li> <li style=""list-style: none;""> <ul> <li>distance to nearest cluster center should almost always be smaller with more clusters</li> <li>it only isn’t when you have bad luck in your randomization</li> <li>cross-validation can’t solve this problem</li> <li style=""list-style: none;""> <ul> <li>a different problem than prediction modeling</li> <li style=""list-style: none;""> <ul> <li>you are not trying to predict specific values</li> <li>you are determining whether any center is close to a given point</li> </ul> </li> <li>more clusters cover the space more thoroughly</li> <li>so distortion will often be smaller with more clusters, even if you cross-validate</li> </ul> </li> <li>solution: </li> <li style=""list-style: none;""> <ul> <li>penalize models with more clusters, according to how much extra fit would be expected from the additional clusters</li> <li>can use the Bayesian Information Criterion or Akaike Information Criterion (not just cross-validation)</li> <li>using an informational criterion</li> <li style=""list-style: none;""> <ul> <li>assess how much fit would be spuriously expected from a random N centroids (without allowing the centroids to move)</li> <li>assess how much fit you actually had</li> <li>find the difference</li> </ul> </li> <li>so how many clusters?</li> <li style=""list-style: none;""> <ul> <li>try several values of k</li> <li>find “best-fitting” set of clusters for each value of k</li> <li>choose k with best value of BIC (or AIC)</li> <li>alternate approach (not data driven): “why am I conducting cluster analysis?”</li> <li style=""list-style: none;""> <ul> <li>if your goal is to just discover qualitatively interesting patterns in the data, you may want to do something simpler than using an information criterion — add clusters until you don’t get interesting new clusters anymore</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>distance</li> <li style=""list-style: none;""> <ul> <li>usually Euclidean distance </li> <li>distance from A to B in two dimensions</li> <li>Euclidean distance can be computed for an arbitrary number of dimensions</li> </ul> </li> </ul>; <p>Chapter 7 Video 6</p> <p> </p> <div>knowledge inference: Q-Matrix</div> <div> <ul> <li>what is the Q-Matrix</li> <li style=""list-style: none;""> <ul> <li>a table, where rows are items, and columns are skills</li> <li>also called a KC (knowledge component) Model, or a skill-item mapping</li> </ul> </li> <li>how do we get a skill-item mapping?</li> <li style=""list-style: none;""> <ul> <li>automatic model discovery</li> <li style=""list-style: none;""> <ul> <li>learn the mapping between items and skills solely from data</li> <li>recent interest in non-negative matrix factorization; lots of linear algebra</li> <li>first question - how many skills do we use? this is determined empirically.</li> <li style=""list-style: none;""> <ol> <li>try 1 skill</li> <li>try 1 more skill than previous model</li> <li>does the new model do better than the previous model? if so, go to step 2; if not, quit and use the previous model.</li> </ol> </li> <li>for each number of skills, the algorithm will be run a certain number of times, with a different (random) initial assignment of items to skills. this avoids local minima.</li> <li>next, take a set of passes through the table. systematically look at whether flipping each 1 to 0 (and each 0 to 1). produces a better model.</li> <li style=""list-style: none;""> <ul> <li>continue this process a predetermined number of times, or until a pass results in no changes.</li> </ul> </li> <li>how do we know whether it is a better model</li> <li style=""list-style: none;""> <ul> <li>Barnes et al.’s definition</li> <li style=""list-style: none;""> <ul> <li>better models have the property that if a student knows skill X. and item 1 and item 2 both have skill X. then a student who gets item 1 right will be more likely to get item 2 right. item 1 wrong -&gt; item 2 wrong. item 2 right -&gt; item 1 right. item 2 wrong -&gt; item 1 wrong</li> <li>given a skill-item mapping, you can predict, for each combination of skills whether a student should get each item correct or not</li> <li>a model’s degree of error is based on how many item-student pairs the prediction gets wrong</li> <li>it assumes no learning</li> </ul> </li> <li>subtlety</li> <li style=""list-style: none;""> <ul> <li>is skill conjunctive? (need all relevant skills to get an item right)</li> <li>is sill compensatory? (any relevant skill leads to getting an item right)</li> </ul> </li> <li>alternate test of model goodness</li> <li style=""list-style: none;""> <ul> <li>look at student improvement over time</li> <li>fit a model like PFA or BKT, see how well it fits data, given the skill-item mapping</li> </ul> </li> </ul> </li> </ul> </li> <li>hand-development and refinement</li> <li style=""list-style: none;""> <ul> <li>the original way that Q-Matrices were created</li> <li>a domain expert creates the Q-Matrix using knowledge engineering</li> <li>strategies for Q-matrix refinement</li> <li style=""list-style: none;""> <ul> <li>try to smooth learning curves</li> <li>look for skills with no apparent learning</li> <li>look for problems with unexpected error rates</li> <li>tool: pittsburgh science of learning center datashop</li> <li style=""list-style: none;""> <ul> <li><a href=""http://pslcdatashop.web.cmu.edu"">pslcdatashop.web.cmu.edu</a></li> </ul> </li> </ul> </li> <li>learning curve</li> <li style=""list-style: none;""> <ul> <li>shows relationship between about of practice and performance</li> <li>spikes in learning curves, often imply two (or more) skills are being treated as a single skill</li> <li>can inspect curves for individual skills - many curves show a reasonable decline. some do not -&gt; opportunity to improve model (can be teaching really bad)</li> <li>also look for problems with unexpected error rates (if actual error rate is much higher than predicted error rate, need to look at it -&gt; might be the skill did not fit what you think it is)</li> </ul> </li> <li>datashop can apply model for you</li> <li style=""list-style: none;""> <ul> <li>applies a mathematical model called LFA (similar to PFA) to data</li> <li>can give AIC and BIC goodness measures for different skill-item mappings</li> </ul> </li> </ul> </li> <li>hybrid approaches</li> </ul> </li> </ul> </div>","","","","","","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZXQP2EJP","videoRecording","2016","Georgia Tech","Cross Validation","","","","","https://www.youtube.com/watch?v=sFO2ff-gTh0","","2016-09-09","2017-09-12 14:45:30","2017-09-12 14:45:30","2016-09-09 19:37:11","","","","","","","","","","","","Youtube","","","","","","","","","","<ul style=""box-sizing: border-box; padding-left: 2em; text-align: start; text-indent: 0px; background-color: #ffffff;""> <li>This video introduced the cross validation concept, including the training set and testing set, overfit, k-fold.</li> <li>use a model that is complex enough to fit the data without causing problems on the test set </li> <li>k-fold: goodness of the fit, is to average all the errors from all models together. pick a model with lowest error.</li> </ul>","","https://www.youtube.com/watch?v=sFO2ff-gTh0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J9CBV4PN","webpage","","","Data wrangling cheatsheet.pdf","","","","","http://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf","","","2017-10-05 13:35:04","2017-10-05 13:35:04","2017-10-05 13:31:42","","","","","","","","","","","","","","","","","","","","","","<ul> <li>dplyr::tbl_df()</li> <li>dplyr::glimpse()</li> <li>dplyr::%&gt;%</li> <li>tidy data: each variable is saved in its own column. each observation is saved in its own row.</li> <li>reshape the data</li> <li style=""list-style: none;""> <ul> <li>tidyr: gather(), spread(), separate(), unite()</li> <li>dplyr: data_frame(), arrange(), rename()</li> </ul> </li> <li>subset observations (dplyr)</li> <li style=""list-style: none;""> <ul> <li>filter(), distinct(), sample_frac(), sample_n(), slice(), top_n()</li> <li>%in%: group membership</li> </ul> </li> <li>subset variables (dplyr)</li> <li style=""list-style: none;""> <ul> <li><span style=""background-color: #ffffff;"">select()</span></li> <li>some helper functions: contains(): ends_with(), everything(), matches(). num_range(), one_of(), starts_with().</li> </ul> </li> <li><span style=""background-color: #ffffff;"">summaries data (dplyr)</span></li> <li style=""list-style: none;""> <ul> <li>summarise():</li> <li><span style=""background-color: #ffffff;"">summarise_each():</span></li> <li><span style=""background-color: #ffffff;"">count()</span></li> <li><span style=""background-color: #ffffff;"">first(), last(), nth(), n(), n_distinct(), min(), max(), mean(), median(), var(), sd()</span></li> </ul> </li> <li><span style=""background-color: #ffffff;"">make new variables (dplyr)</span></li> <li style=""list-style: none;""> <ul> <li><span style=""background-color: #ffffff;"">mutate()</span></li> <li>mutate_each()</li> <li><span style=""background-color: #ffffff;"">transmute()</span></li> </ul> </li> <li>combine data sets (dplyr)</li> <li style=""list-style: none;""> <ul> <li><span style=""background-color: #ffffff;"">mutating joins: left_join(), right_join(), inner_join(), full_join()</span></li> <li><span style=""background-color: #ffffff;"">filtering joins: semi_join(), anti_join()</span></li> <li>set operations: intersect(), union(), setdiff()</li> <li><span style=""background-color: #ffffff;"">binding: bind_rows(), bind_cols()</span></li> </ul> </li> <li><span style=""background-color: #ffffff;"">group data (dplyr)</span></li> <li style=""list-style: none;""> <ul> <li><span style=""background-color: #ffffff;"">group_by()</span></li> <li><span style=""background-color: #ffffff;"">ungroup()</span></li> <li><span style=""background-color: #ffffff;"">.. %&gt;% group_by() %&gt;% summarise()</span></li> <li>.. %&gt;% group_by() %&gt;% mutate()</li> </ul> </li> </ul>","/Users/cici/Zotero/storage/9SJEHIAA/data-wrangling-cheatsheet.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N6NE6QZX","webpage","","","Ethics and Learning Analytics: Charting the (Un)Charted.pdf","","","","","http://oro.open.ac.uk/49456/3/hla17-chapter4%20%281%29.pdf","","","2017-10-05 13:35:32","2017-10-05 13:35:32","2017-10-03 03:52:56","","","","","","","","","","","","","","","","","","","","","","<div style=""-en-clipboard: true;"">Thoughts and Feelings:</div> <ul> <li>It is good to see some people take ethic in learning analytics seriously. I am deeply impressed by that learning analytics is a MORAL practice, and the problems are not only privacy as we usually thought. The “moral practice"" has shown the respectiveness towards data, and more importantly, the people/intention behind the usage of d<span style=""font-family: 'Helvetica Neue';"">ata. It has to be student-centered without doubt, and they are supposed to have choices to opt-in or opt-out. </span><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">Central to this issue is the question of “who benefits?” A lot of other issues will also concern on the technical aspects (including interpretation of the data etc.) and current policy / organization culture. It will be great if more people from different areas their attention could be attracted on this essential issue, and collaborate to solve it.</span></li> </ul> <div> </div> <div><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">Notes: </span></div> <ul> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">consensus of future learning: digital, distributed, data-driven.</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">ethical concerns: data governance, data security, privacy issues</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">location and interpretation of data</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">informed consent, privacy, and the de-identification of data</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">the management, classification, and storage of data</span></li> </ul> </li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">Learning analytics in future will be essentially based on and driven by algorithms and machine learning and we therefore have to consider how algorithms “reinforce, maintain, or even reshape visions of the social world, knowledge, and encounters with information”</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">Accountability, transparency, andregulatory frameworks will be essential elements</span></li> </ul> </li> </ul>","/Users/cici/Zotero/storage/MLXMBQ2U/hla17-chapter4 (1).pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G85HVBMC","webpage","","","Measurement and its Uses in Learning Analytics.pdf","","","","","https://solaresearch.org/wp-content/uploads/2017/05/chapter3.pdf","","","2017-10-05 13:35:55","2017-10-05 13:35:55","2017-10-03 03:52:12","","","","","","","","","","","","","","","","","","","","","","<div style=""-en-clipboard: true;"">Thoughts and Feelings:</div> <ul> <li>I love this paper. I’ve studied several psychometric classes during my undergraduate study, and this article reminds me of lots of important concepts in a nutshell. However, i hope to see some connections between psychometric methods and learning analytics, or the implications for future learning analytics / psychometric development.</li> <li>I am interested in the multidimensional construct. It is true that </li> </ul> <div> </div> <div>Notes: </div> <div><span style=""color: #0433ff; font-family: 'Helvetica Neue';"">question on P37 P38 P39 GROW MODEL prediction and explanation</span></div> <ul> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">The use of tests and questionnaires is a matter of both efficiency and standardization. In learninganalytics, efficient collection of data is usually not the problem, but the lack of standardization can make it challenging to account for measurement error.</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">reliability: sample-dependent (in true score theory), model-dependent (more complicated models)</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">reliability coefficient - Cronbach’s alpha</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">test-retest reliability</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">inter-rater reliability - Cohen’s kappa</span></li> </ul> </li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">validity: evidence and theory support the interpretationsof test scores for proposed uses of tests</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">response process</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">internal structure of the instrument</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">convergent and discriminant evidence</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">criterion references (including predictive criteria)</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">generalizability</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">types of response bias: acquiescence bias. social desirability bias, bias from extreme and moderate types of responders, </span><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">intentional rapid guessing behavior</span></li> </ul> </li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">measurement models</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">factor analysis</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">true score theory / classical test theory</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">EFA, PCA, CFA, path analysis, later growth models, SEM</span></li> </ul> </li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">latent dirichlet allocation (LDA), model-based cluster analysis</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">item response theory (IRT)</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">growth models: Bayesian knowledge tracking (BKT), Additive factors models (AFM), Learning curve analysis</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">cognitive diagnosis models (CDM)</span></li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">explanation and prediction</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">“in explanatory modelling the focus is on minimizing bias to obtain the most accurate representation of theunderlying theory. In contrast, predictive modellingseeks to minimize the combination of bias and vari-ance, occasionally sacri cing theoretical accuracyfor improved empirical precision”</span></li> </ul> </li> <li><span style=""font-size: 14px; font-family: 'Helvetica Neue';"">learning analytics as a “middle space” between learning scienceand analytics; Perhaps it may also be thought of asoccupying a methodological middle space between explanatory and predictive approaches.</span></li> </ul>","/Users/cici/Zotero/storage/H9QS9AKM/chapter3.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"99USRZSU","encyclopediaArticle","","","k-Means Clustering","","","","","https://www.cs.uic.edu/~wilkinson/Applets/cluster.html","","","2017-10-26 17:19:32","2017-10-26 17:21:40","","","","","","","","","","","","","","","","","","","","","","","<p>use of K-means clustering:</p> <ul> <li>The k-means clustering algorithm classifies n points into k clusters by assigning each point to the cluster whose average value on a set of p variables is nearest to it by some distance measure (usually Euclidean) on that set. ／ If n points are embedded in a p-dimensional space, then k clusters are summarized by their respective centroids (average of the cluster members' coordinates) in that space.</li> <li>k-means is most suited for separating convex clusters (clusters in which any line passing through a cluster intersects its boundary only twice).</li> <li>finding a satisfactory set of centroids given a set of data. <ul> <li>The simplest is to pick an initial set of centroid seeds randomly (assuming we know how many clusters we want) and to assign each point to its closest seed.</li> <li>If there really are blobs of points, we do much better to begin with locations that are relatively close to the center of these blobs. [stagewise method]</li> </ul> </li> <li>“we need to know k to find clusters and we need to identify clusters to determine k.” - Hartigan gives an approximate F statistic that can be used to test the ""significance"" of this reduction, but a simple method that works well for most datasets is to look for a <strong>proportional reduction in error (PRE)</strong> of about <strong>.4</strong> or better to justify a split. PRE is the ratio of reduction in sum of squares to the previous sum of squares. Use the PRE method to determine the number of clusters present.</li> </ul> <p>limitations of K-means clustering:</p> <ul> <li>If your data contain doughnut-shaped or wormy-shaped clusters, don't expect k-means to find them.</li> <li>There will also be rare instances when clearly separated blobs are not identified. These are cases where the PRE statistic misses the cutoff (.4) by a small amount. There is always a tradeoff between false positives and false negatives, but we could improve this situation a bit by using more information than simple sums of squares.</li> <li>Data mining programs incorporating k-means sometimes ignore the subtleties of the algorithm. However, it might find nice clusters even when they don't exist in the data.<span style=""color: #000000; font-family: -webkit-standard; font-size: medium; font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; display: inline !important; float: none;""><br /></span></li> </ul>","","https://www.cs.uic.edu/~wilkinson/Applets/cluster.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R4QNTA6C","document","","","Assignment 3.Rmd","","","","","","","","2017-12-12 06:39:42","2017-12-12 06:39:42","","","","","","","","","","","","","","","","","","","","","","","","/Users/cici/Desktop/Columbia/Courses/Education Data Mining/EDM_Siyan Yin/assignment-3-ysycici/Assignment 3 Instructions.Rmd; /Users/cici/assignment-3-ysycici/Assignment 3 Instructions.Rmd; /Users/cici/Desktop/Columbia/Courses/Education Data Mining/EDM_Siyan Yin/assignment-3-ysycici/plot1.png; /Users/cici/Desktop/Columbia/Courses/Education Data Mining/EDM_Siyan Yin/assignment-3-ysycici/plot2.png","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V6LUWE55","journalArticle","","","Predictive Modelling in Teaching and Learning","","","","","","","","2017-12-12 06:57:46","2017-12-12 06:58:00","","","","","","","","","","","","","","","","","","","","","","","<ul> <li>This paper mainly focus on the basic concepts and issues of predictive modeling in teaching and learning.</li> <li>explanatory modeling is a post-hoc and reflective activity aimed at generating an understanding of a phenomenon. the largest methodological difference between the two modeling approaches is in how they address the issue of generalizability. </li> <li>several strategies for producing hold out datasets: k-fold cross validation, leave-one-out cross validation, randomized subsampling, and application-specific strategies.</li> <li>several factors make predictive modeling more difficult or less appropriate</li> <li style=""list-style: none;""> <ul> <li>data sparsity / missing data</li> <li>noisy data</li> <li>in some domains, inferences produced by predictive models may be at odds with ethical or equitable practice</li> </ul> </li> <li>event-data: largely student activity-based, and is derived from the larding technologies that tudents interact with. this data is large and complex, requires significant effort to convert into meaningful features for machines learning.</li> <li>four types of data: categorical, ordinal, interval, and ratio</li> <li style=""list-style: none;""> <ul> <li>in practice, ordinal is often treated as categorical. interval and ratio are considered as numeric.</li> <li>classification algorithms are used to predict categorical values, while regression algorithms are used to predict numeric values</li> </ul> </li> <li>feature selection</li> <li style=""list-style: none;""> <ul> <li>collect more information rather than less</li> <li>examine the correlation between features: either remove highly correlated attributes (the multicollinearity problem in regression analysis), or apply a transformation to the features to eliminate the correlation (in practice, the dependencies between features are often ignored)</li> <li>missing values in a dataset: methods depends on whether data is missing is because it is unknown or because it is not applicable</li> <li style=""list-style: none;""> <ul> <li>remove the attributes (columns) or instances (rows) that have missing values (drawback like in domains where the total amount of data is quite small)</li> <li>infer the missing values from the other known data: replace missing values with a normal value, such as the mean of the known values. fill in missing values in records by finding other similar records in the dataset, and copying the missing values from their records</li> </ul> </li> </ul> </li> <li>methods for building predictive models</li> <li style=""list-style: none;""> <ul> <li>basic assumption: the relationship that exist in the data gathered in the past will still exist in the future</li> <li>linear regression, logistic regression, nearest neighbors classifiers, decision trees, naive bayes classifiers, bayesian networks, support vector machine, neural networks, ensemble methods</li> <li>once a given technique has shown promise, time is better spent reflecting on the fundamental assumptions of classifiers, exploring ensembles of classifiers, or tuning the parameters of particular methods being employed</li> </ul> </li> <li>evaluating a model: compare two models. k-fold cross validation.</li> <li>challenges and opportunities</li> <li style=""list-style: none;""> <ul> <li>supporting non-computer scientists in predictive modeling activities</li> <li>creating community-led educational data science challenge initiatives</li> <li>engaging in second order predictive modeling. second order predictive models - include historical knowledge as to the effects of and intervention in the model itself </li> </ul> </li> </ul>","","https://solaresearch.org/hla-17/hla17-chapter5/","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EXI4SFVT","journalArticle","","","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data.","","","","","","","","2017-12-12 06:59:22","2017-12-12 06:59:32","","","","","","","","","","","","","","","","","","","","","","","<ul> <li>The main idea of this article is to use examples to illustrate that explanatory models can improve learning outcomes and/or learning theories.</li> <li>It reminds me of the CDM (cognitive diagnostic model) that I’ve learned before, and I realized that limits of using expert opinions as a way of determining the Q-matrix at that time, and what I could do differently now.</li> <li style=""list-style: none;""> <ul> <li>transitional ways of constructing cognitive models: structured interviews, think-aloud protocols, rational analysis, and labeling by domain experts. they require human input and are often time consuming, subjective. Expert-engineered cognitive models often ignore content distinctions that are important for novice learners.</li> </ul> </li> <li>It also provides more bottom-up methods of creating stereotyped groups of students. This method yielded student groups that are readily interpretable and potentially actionable (prior attempts include K-means and spectral clustering)</li> <li><span style=""font-size: 9pt; font-family: Lora;"" title=""Page 5"">For a model to be explanatory, one should be able to under</span><span style=""font-size: 9pt; font-family: Lora;"" title=""Page 5"">stand</span> <span style=""font-size: 9pt; font-family: Lora; font-style: italic;"" title=""Page 5"">why</span> <span style=""font-size: 9pt; font-family: Lora;"" title=""Page 5"">the model achieves better predictive accuracy than alternatives. In addition, the understanding of this</span> <span style=""font-size: 9pt; font-family: Lora; font-style: italic;"" title=""Page 5"">why</span> <span style=""font-size: 9pt; font-family: Lora;"" title=""Page 5"">should either advance our understanding of how learners learn the relevant material or have clear implications for instructional improvements, or both.</span></li> <li>AFM: Additive factors model</li> <li>DFA: Difficulty factors assessment</li> <li>KC: Knowledge component</li> <li>Learning factors analysis (LFA) was developed to automate the data-driven method of KC model refinement to further alleviate demands on human time.</li> <li><span style=""font-family: Lora;"">predictive models: aim to find a combination of features that best predict outcomes; they are typically assessed by their accuracy in predicting held-out data</span></li> <li><span style=""font-family: Lora;"">explanatory models: seek to identify interpretable causal relationships between constructs that can be either observed or inferred from the data.</span></li> <li><span style=""font-family: Lora;"">EDM research has focused on developing two types of models</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: Lora;"">statistical models: drive the outer loop of intelligent tutoring systems based on observable features of students’ performance as they learn</span></li> <li><span style=""font-family: Lora;"">cognitive models: representations of the knowledge space (facts, concepts, skills) underlying a particular educational domain</span></li> </ul> </li> <li><span style=""font-family: Lora;"">common characteristics of explanatory models</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: Lora;"">tend to start with “clean” independent variables that have either simple functions or map to clearly defined constructs</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: Lora;"">incorporating some human time and thought into defining and labeling these independent variables up front can greatly improve the explanatory power of the resulting model</span></li> </ul> </li> <li><span style=""font-family: Lora;"">having parameters that map to interpretable constructs</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-size: 12px; font-family: Lora;"">actionability: the dependent variable maps to a well-defined&amp;nbsp;construct</span></li> </ul> </li> <li><span style=""font-family: Lora;"">having fewer parameters overall</span></li> <li style=""list-style: none;""> <ul> <li><span style=""font-family: Lora;"">fewer independent variables. AFM has only one parameter for each student and two parameters for each knowledge component</span></li> </ul> </li> <li><span style=""font-family: Lora;"">involving human input early in the model development process</span></li> </ul> </li> </ul>","","https://solaresearch.org/hla-17/hla17-chapter6/","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""